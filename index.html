<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/bio.jpg"/><link rel="stylesheet" href="/_next/static/css/78c4370b96c05382.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-679b75d1c4c2027c.js"/><script src="/_next/static/chunks/4bd1b696-70b6d399998de86a.js" async=""></script><script src="/_next/static/chunks/684-5aaa8290a129f299.js" async=""></script><script src="/_next/static/chunks/main-app-480fe316c9db0337.js" async=""></script><script src="/_next/static/chunks/461-a9a5d7b05a71d978.js" async=""></script><script src="/_next/static/chunks/874-6cc630662f3664af.js" async=""></script><script src="/_next/static/chunks/291-e39730cc9327e39b.js" async=""></script><script src="/_next/static/chunks/app/layout-4cf029633e6d5428.js" async=""></script><script src="/_next/static/chunks/178-595a94b9af1e67b5.js" async=""></script><script src="/_next/static/chunks/748-97f90665cfe632a2.js" async=""></script><script src="/_next/static/chunks/app/page-6c80dddde2d5f2d2.js" async=""></script><link rel="icon" href="/favicon.ico" type="image/svg+xml"/><link rel="dns-prefetch" href="https://jialeliu.com"/><link rel="preconnect" href="https://jialeliu.com" crossorigin=""/><link rel="preload" as="font" type="font/woff2" href="https://jialeliu.com/fonts/georgiab.woff2" crossorigin=""/><script>
              try {
                const theme = localStorage.getItem('theme-storage');
                const parsed = theme ? JSON.parse(theme) : null;
                const setting = parsed?.state?.theme || 'system';
                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));
                var root = document.documentElement;
                root.classList.add(effective);
                root.setAttribute('data-theme', effective);
              } catch (e) {
                var root = document.documentElement;
                root.classList.add('light');
                root.setAttribute('data-theme', 'light');
              }
            </script><script>
    try {
      const cfg = {"enabled":true,"locales":["en"],"defaultLocale":"en","mode":"auto","fixedLocale":"en","persist":true,"switcher":true,"labels":{"en":"English"}};
      const storageKey = 'locale-storage';
      const normalize = (value) => typeof value === 'string' ? value.trim().replace('_', '-').toLowerCase() : '';
      const matchLocale = (candidate) => {
        const normalized = normalize(candidate);
        if (!normalized) return null;
        if (cfg.locales.includes(normalized)) return normalized;
        const language = normalized.split('-')[0];
        if (cfg.locales.includes(language)) return language;
        return null;
      };

      let resolved = null;

      if (cfg.persist) {
        resolved = matchLocale(localStorage.getItem(storageKey));
      }

      if (!resolved) {
        if (cfg.mode === 'fixed') {
          resolved = cfg.fixedLocale;
        } else {
          resolved = matchLocale(navigator.language);
        }
      }

      if (!resolved) {
        resolved = cfg.defaultLocale;
      }

      const root = document.documentElement;
      root.lang = resolved;
      root.setAttribute('data-locale', resolved);

      if (cfg.persist) {
        localStorage.setItem(storageKey, resolved);
      }
    } catch (e) {
      const root = document.documentElement;
      root.lang = 'en';
      root.setAttribute('data-locale', 'en');
    }
  </script><title>Jingyao Wang</title><meta name="description" content="PhD student at the University of Example."/><meta name="author" content="Jingyao Wang"/><meta name="keywords" content="Jingyao Wang,PhD,Research,Institute of Software Chinese Academy of Sciences"/><meta name="creator" content="Jingyao Wang"/><meta name="publisher" content="Jingyao Wang"/><meta property="og:title" content="Jingyao Wang"/><meta property="og:description" content="PhD student at the University of Example."/><meta property="og:site_name" content="Jingyao Wang&#x27;s Academic Website"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Jingyao Wang"/><meta name="twitter:description" content="PhD student at the University of Example."/><link rel="icon" href="/favicon.ico"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-sans antialiased"><div style="visibility:hidden"><nav class="fixed top-0 left-0 right-0 z-50" data-headlessui-state=""><div class="transition-all duration-300 ease-out bg-transparent" style="transform:translateY(-100px)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center h-16 lg:h-20"><div class="flex-shrink-0" tabindex="0"><a class="text-xl lg:text-2xl font-serif font-semibold text-primary hover:text-accent transition-colors duration-200" href="/">Jingyao Wang</a></div><div class="hidden lg:block"><div class="ml-10 flex items-center space-x-3"><div class="relative flex items-baseline space-x-1"><a data-nav-href="/" class="relative px-3 py-2 text-sm font-medium rounded-lg transition-colors duration-150 text-primary" href="/">About</a><a data-nav-href="/publications" class="relative px-3 py-2 text-sm font-medium rounded-lg transition-colors duration-150 text-neutral-600" href="/publications/">Publications</a><a data-nav-href="/teaching" class="relative px-3 py-2 text-sm font-medium rounded-lg transition-colors duration-150 text-neutral-600" href="/teaching/">Teaching</a><a data-nav-href="/awards" class="relative px-3 py-2 text-sm font-medium rounded-lg transition-colors duration-150 text-neutral-600" href="/awards/">Awards</a><a data-nav-href="/services" class="relative px-3 py-2 text-sm font-medium rounded-lg transition-colors duration-150 text-neutral-600" href="/services/">Services</a><a data-nav-href="/cv" class="relative px-3 py-2 text-sm font-medium rounded-lg transition-colors duration-150 text-neutral-600" href="/cv/">CV</a></div><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div></div></div><div class="lg:hidden flex items-center space-x-2"><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div><button class="inline-flex items-center justify-center p-2 rounded-md text-neutral-600 hover:text-primary hover:bg-neutral-100 dark:hover:bg-neutral-800 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-accent transition-colors duration-200" id="headlessui-disclosure-button-Â«R7pdbÂ»" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open main menu</span><div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></div></button></div></div></div></div></nav><main class="min-h-screen pt-16 lg:pt-20"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8 bg-background min-h-screen"><div class="grid grid-cols-1 lg:grid-cols-3 gap-12"><div class="lg:col-span-1"><div class="sticky top-8" style="opacity:0;transform:translateY(20px)"><div class="w-64 h-64 mx-auto mb-6 rounded-2xl overflow-hidden shadow-lg hover:shadow-xl transition-all duration-200 hover:scale-105"><img alt="Jingyao Wang" width="256" height="256" decoding="async" data-nimg="1" class="w-full h-full object-cover object-[32%_center]" style="color:transparent" src="/bio.jpg"/></div><div class="text-center mb-6"><h1 class="text-3xl font-serif font-bold text-primary mb-2">Jingyao Wang</h1><p class="text-lg text-accent font-medium mb-1">PhD Student</p><p class="text-neutral-600 mb-2">Institute of Software Chinese Academy of Sciences</p></div><div class="flex flex-wrap justify-center gap-3 sm:gap-4 mb-6 relative px-2"><div class="relative"><button class="p-2 sm:p-2 transition-colors duration-200 text-neutral-600 dark:text-neutral-400 hover:text-accent" aria-label="Email"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M21.75 6.75v10.5a2.25 2.25 0 0 1-2.25 2.25h-15a2.25 2.25 0 0 1-2.25-2.25V6.75m19.5 0A2.25 2.25 0 0 0 19.5 4.5h-15a2.25 2.25 0 0 0-2.25 2.25m19.5 0v.243a2.25 2.25 0 0 1-1.07 1.916l-7.5 4.615a2.25 2.25 0 0 1-2.36 0L3.32 8.91a2.25 2.25 0 0 1-1.07-1.916V6.75"></path></svg></button></div><div class="relative"><button class="p-2 sm:p-2 transition-colors duration-200 text-neutral-600 dark:text-neutral-400 hover:text-accent" aria-label="Location"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M15 10.5a3 3 0 1 1-6 0 3 3 0 0 1 6 0Z"></path><path stroke-linecap="round" stroke-linejoin="round" d="M19.5 10.5c0 7.142-7.5 11.25-7.5 11.25S4.5 17.642 4.5 10.5a7.5 7.5 0 1 1 15 0Z"></path></svg></button></div><a href="https://scholar.google.com/citations?user=btThEsYAAAAJ" target="_blank" rel="noopener noreferrer" class="p-2 sm:p-2 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="Google Scholar"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-5 w-5"><path stroke-linecap="round" stroke-linejoin="round" d="M4.26 10.147a60.438 60.438 0 0 0-.491 6.347A48.62 48.62 0 0 1 12 20.904a48.62 48.62 0 0 1 8.232-4.41 60.46 60.46 0 0 0-.491-6.347m-15.482 0a50.636 50.636 0 0 0-2.658-.813A59.906 59.906 0 0 1 12 3.493a59.903 59.903 0 0 1 10.399 5.84c-.896.248-1.783.52-2.658.814m-15.482 0A50.717 50.717 0 0 1 12 13.489a50.702 50.702 0 0 1 7.74-3.342M6.75 15a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm0 0v-3.675A55.378 55.378 0 0 1 12 8.443m-7.007 11.55A5.981 5.981 0 0 0 6.75 15.75v-1.5"></path></svg></a><a href="https://orcid.org/my-orcid?orcid=0000-0003-1782-8704" target="_blank" rel="noopener noreferrer" class="p-2 sm:p-2 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="ORCID"><svg viewBox="0 0 24 24" fill="currentColor" class="h-5 w-5" xmlns="http://www.w3.org/2000/svg"><path d="M12 0C5.372 0 0 5.372 0 12s5.372 12 12 12 12-5.372 12-12S18.628 0 12 0zM7.369 4.378c.525 0 .947.431.947.947s-.422.947-.947.947a.95.95 0 0 1-.947-.947c0-.525.422-.947.947-.947zm-.722 3.038h1.444v10.041H6.647V7.416zm3.562 0h3.9c3.712 0 5.344 2.653 5.344 5.025 0 2.578-2.016 5.025-5.325 5.025h-3.919V7.416zm1.444 1.303v7.444h2.297c3.272 0 4.022-2.484 4.022-3.722 0-2.016-1.284-3.722-4.097-3.722h-2.222z"></path></svg></a><a href="https://github.com/WangJingyao07" target="_blank" rel="noopener noreferrer" class="p-2 sm:p-2 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a><a href="https://www.zhihu.com/people/wang-dou-ya-11" target="_blank" rel="noopener noreferrer" class="p-2 sm:p-2 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="Zhihu"><svg viewBox="0 0 24 24" fill="currentColor" class="h-5 w-5" xmlns="http://www.w3.org/2000/svg"><path d="M5.721 0C2.251 0 0 2.25 0 5.719V18.28C0 21.751 2.252 24 5.721 24h12.56C21.751 24 24 21.75 24 18.281V5.72C24 2.249 21.75 0 18.281 0zm1.964 4.078c-.271.73-.5 1.434-.68 2.11h4.587c.545-.006.445 1.168.445 1.171H9.384a58.104 58.104 0 01-.112 3.797h2.712c.388.023.393 1.251.393 1.266H9.183a9.223 9.223 0 01-.408 2.102l.757-.604c.452.456 1.512 1.712 1.906 2.177.473.681.063 2.081.063 2.081l-2.794-3.382c-.653 2.518-1.845 3.607-1.845 3.607-.523.468-1.58.82-2.64.516 2.218-1.73 3.44-3.917 3.667-6.497H4.491c0-.015.197-1.243.806-1.266h2.71c.024-.32.086-3.254.086-3.797H6.598c-.136.406-.158.447-.268.753-.594 1.095-1.603 1.122-1.907 1.155.906-1.821 1.416-3.6 1.591-4.064.425-1.124 1.671-1.125 1.671-1.125zM13.078 6h6.377v11.33h-2.573l-2.184 1.373-.401-1.373h-1.219zm1.313 1.219v8.86h.623l.263.937 1.455-.938h1.456v-8.86z"></path></svg></a></div><div class="bg-neutral-100 dark:bg-neutral-800 rounded-lg p-4 mb-6 hover:shadow-lg transition-all duration-200 hover:scale-[1.02]"><h3 class="font-semibold text-primary mb-3">Research Interests</h3><div class="space-y-2 text-sm text-neutral-700 dark:text-neutral-500"><div>MLLM/LLM Reasoning</div><div>Embodied AI</div><div>Transfer Learning</div></div></div><div class="flex justify-center"><div class="relative"><button class="flex items-center space-x-2 px-4 py-2 rounded-lg font-medium text-sm transition-all duration-200 bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-500 hover:bg-red-50 dark:hover:bg-red-900/20 hover:text-red-600 dark:hover:text-red-400 cursor-pointer" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-4 w-4"><path stroke-linecap="round" stroke-linejoin="round" d="M21 8.25c0-2.485-2.099-4.5-4.688-4.5-1.935 0-3.597 1.126-4.312 2.733-.715-1.607-2.377-2.733-4.313-2.733C5.1 3.75 3 5.765 3 8.25c0 7.22 9 12 9 12s9-4.78 9-12Z"></path></svg><span>Like</span></button></div></div></div></div><div class="lg:col-span-2 space-y-8"><section id="about" class="scroll-mt-24 space-y-8"><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">About</h2><div class="text-neutral-700 dark:text-neutral-600 leading-relaxed"><p class="mb-4 last:mb-0">I am a second-year PhD student at <a href="http://www.is.cas.cn/" node="[object Object]" target="_blank" rel="noopener noreferrer" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm">ISCAS</a>, <a href="https://www.ucas.ac.cn/" node="[object Object]" target="_blank" rel="noopener noreferrer" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm">UCAS</a>, advised by <a href="https://people.ucas.ac.cn/~cwzheng?language=en" node="[object Object]" target="_blank" rel="noopener noreferrer" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm">Prof. Changwen Zheng</a></p>
<p class="mb-4 last:mb-0">Prior to this, I obtained a B.E. degree with First Class Honours in Beijing University of Technology.</p>
<p class="mb-4 last:mb-0">My research interest includes MLLM/LLM Reasoning, Embodied AI, and Transfer Learning. I am maintaining two popular projects on LLM post-training and meta-learning <a href="https://github.com/WangJingyao07/Awesome-GRPO" node="[object Object]" target="_blank" rel="noopener noreferrer" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm">Awesome-GRPO</a> and <a href="https://wangjingyao07.github.io/Awesome-Meta-Learning-Platform/" node="[object Object]" target="_blank" rel="noopener noreferrer" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm">Awesome-META+</a></p></div></section><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">News</h2><div class="space-y-3"><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2026-02</span><p class="text-sm text-neutral-700">One work has been accepted by CVPR 2026 ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2026-01</span><p class="text-sm text-neutral-700">One work has been accepted by WWW 2026 ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-11</span><p class="text-sm text-neutral-700">One work has been accepted by ASOC ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-10</span><p class="text-sm text-neutral-700">Two works have been accepted by AAAI 2026 ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-09</span><p class="text-sm text-neutral-700">One work has been accepted by NeurIPS 2025 ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-07</span><p class="text-sm text-neutral-700">One work has been accepted by ACMMM 2025 ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-05</span><p class="text-sm text-neutral-700">Two works have been accepted by ICML 2025 ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2024-07</span><p class="text-sm text-neutral-700">One work has been accepted by TMM ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2024-05</span><p class="text-sm text-neutral-700">One work has been accepted by IJCV ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2024-04</span><p class="text-sm text-neutral-700">One work has been accepted by IJCAI 2024 ðŸŽ‰</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2023-02</span><p class="text-sm text-neutral-700">One work has been accepted by ACM TOMM ðŸŽ‰</p></div></div></section><section style="opacity:0;transform:translateY(20px)"><div class="flex items-center justify-between mb-4"><h2 class="text-2xl font-serif font-bold text-primary">Selected Publications</h2><a class="text-accent hover:text-accent-dark text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" href="/publications/">View All<!-- --> â†’</a></div><div class="space-y-4"><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><h3 class="font-semibold text-primary mb-2 leading-tight">Group causal policy optimization for post-training large language models</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" underline underline-offset-4 decoration-neutral-400">Ziyin Gu</span>, </span><span><span class="font-semibold text-accent underline underline-offset-4 decoration-accent">Jingyao Wang</span>, </span><span><span class=" ">Ran Zuo</span>, </span><span><span class=" ">Chuxiong Sun</span>, </span><span><span class=" ">Zeen Song</span>, </span><span><span class=" ">Changwen Zheng</span>, </span><span><span class=" ">Wenwen Qiang</span><sup class="ml-0 text-neutral-600 dark:text-neutral-500">â€ </sup></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">AAAI</p></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><h3 class="font-semibold text-primary mb-2 leading-tight">Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" underline underline-offset-4 decoration-neutral-400">Jianqi Zhang</span>, </span><span><span class="font-semibold text-accent underline underline-offset-4 decoration-accent">Jingyao Wang</span>, </span><span><span class=" ">Wenwen Qiang</span><sup class="ml-0 text-neutral-600 dark:text-neutral-500">â€ </sup>, </span><span><span class=" ">Fanjiang Xu</span>, </span><span><span class=" ">Changwen Zheng</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">WWW</p></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><h3 class="font-semibold text-primary mb-2 leading-tight">COPO: Causal-Oriented Policy Optimization for Hallucinations of MLLMs</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" underline underline-offset-4 decoration-neutral-400">Peizheng Guo</span>, </span><span><span class="font-semibold text-accent underline underline-offset-4 decoration-accent">Jingyao Wang</span>, </span><span><span class=" ">Wenwen Qiang</span><sup class="ml-0 text-neutral-600 dark:text-neutral-500">â€ </sup>, </span><span><span class=" ">Jiahuan Zhou</span>, </span><span><span class=" ">Changwen Zheng</span>, </span><span><span class=" ">Gang Hua</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">CVPR</p></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><h3 class="font-semibold text-primary mb-2 leading-tight">Towards the causal complete cause of multi-modal representation learning</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class="font-semibold text-accent ">Jingyao Wang</span>, </span><span><span class=" ">Siyu Zhao</span>, </span><span><span class=" ">Wenwen Qiang</span><sup class="ml-0 text-neutral-600 dark:text-neutral-500">â€ </sup>, </span><span><span class=" ">Jiangmeng Li</span>, </span><span><span class=" ">Changwen Zheng</span>, </span><span><span class=" ">Fuchun Sun</span>, </span><span><span class=" ">Hui Xiong</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">ICML</p></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><h3 class="font-semibold text-primary mb-2 leading-tight">Learning to think: Information-theoretic reinforcement fine-tuning for llms</h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class="font-semibold text-accent ">Jingyao Wang</span>, </span><span><span class=" ">Wenwen Qiang</span><sup class="ml-0 text-neutral-600 dark:text-neutral-500">â€ </sup>, </span><span><span class=" ">Zeen Song</span>, </span><span><span class=" ">Changwen Zheng</span>, </span><span><span class=" ">Hui Xiong</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">NeurIPS</p></div></div></section></section></div></div></div><!--$--><!--/$--><!--$--><!--/$--></main><footer class="border-t border-neutral-200/50 bg-neutral-50/50 dark:bg-neutral-900/50 dark:border-neutral-700/50"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-6"><div class="flex flex-col sm:flex-row justify-between items-center gap-2"><p class="text-xs text-neutral-500">Last updated<!-- -->: <!-- -->March 1, 2026</p><p class="text-xs text-neutral-500 flex items-center"><a href="https://github.com/xyjoey/PRISM" target="_blank" rel="noopener noreferrer">Built with PRISM</a><span class="ml-2">ðŸš€</span></p></div></div></footer></div><script src="/_next/static/chunks/webpack-679b75d1c4c2027c.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n3:I[3719,[\"461\",\"static/chunks/461-a9a5d7b05a71d978.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"291\",\"static/chunks/291-e39730cc9327e39b.js\",\"177\",\"static/chunks/app/layout-4cf029633e6d5428.js\"],\"ThemeProvider\"]\n4:I[310,[\"461\",\"static/chunks/461-a9a5d7b05a71d978.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"291\",\"static/chunks/291-e39730cc9327e39b.js\",\"177\",\"static/chunks/app/layout-4cf029633e6d5428.js\"],\"LocaleProvider\"]\n5:I[4574,[\"461\",\"static/chunks/461-a9a5d7b05a71d978.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"291\",\"static/chunks/291-e39730cc9327e39b.js\",\"177\",\"static/chunks/app/layout-4cf029633e6d5428.js\"],\"default\"]\n6:I[7555,[],\"\"]\n7:I[1295,[],\"\"]\n8:I[2548,[\"461\",\"static/chunks/461-a9a5d7b05a71d978.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"291\",\"static/chunks/291-e39730cc9327e39b.js\",\"177\",\"static/chunks/app/layout-4cf029633e6d5428.js\"],\"default\"]\n9:I[6613,[\"461\",\"static/chunks/461-a9a5d7b05a71d978.js\",\"178\",\"static/chunks/178-595a94b9af1e67b5.js\",\"874\",\"static/chunks/874-6cc630662f3664af.js\",\"748\",\"static/chunks/748-97f90665cfe632a2.js\",\"974\",\"static/chunks/app/page-6c80dddde2d5f2d2.js\"],\"default\"]\n14:I[9665,[],\"MetadataBoundary\"]\n16:I[9665,[],\"OutletBoundary\"]\n19:I[4911,[],\"AsyncMetadataOutlet\"]\n1b:I[9665,[],\"ViewportBoundary\"]\n1d:I[6614,[],\"\"]\n:HL[\"/_next/static/css/78c4370b96c05382.css\",\"style\"]\n2:T57d,\n    try {\n      const cfg = {\"enabled\":true,\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"mode\":\"auto\",\"fixedLocale\":\"en\",\"persist\":true,\"switcher\":true,\"labels\":{\"en\":\"English\"}};\n      const storageKey = 'locale-storage';\n      const normalize = (value) =\u003e typeof value === 'string' ? value.trim().replace('_', '-').toLowerCase() : '';\n      const matchLocale = (candidate) =\u003e {\n        const normalized = normalize(candidate);\n        if (!normalized) return null;\n        if (cfg.locales.includes(normalized)) return normalized;\n        const language = normalized.split('-')[0];\n        if (cfg.locales.includes(language)) return language;\n        return null;\n   "])</script><script>self.__next_f.push([1,"   };\n\n      let resolved = null;\n\n      if (cfg.persist) {\n        resolved = matchLocale(localStorage.getItem(storageKey));\n      }\n\n      if (!resolved) {\n        if (cfg.mode === 'fixed') {\n          resolved = cfg.fixedLocale;\n        } else {\n          resolved = matchLocale(navigator.language);\n        }\n      }\n\n      if (!resolved) {\n        resolved = cfg.defaultLocale;\n      }\n\n      const root = document.documentElement;\n      root.lang = resolved;\n      root.setAttribute('data-locale', resolved);\n\n      if (cfg.persist) {\n        localStorage.setItem(storageKey, resolved);\n      }\n    } catch (e) {\n      const root = document.documentElement;\n      root.lang = 'en';\n      root.setAttribute('data-locale', 'en');\n    }\n  a:T563,Recent advances in large language models (LLMs) have broadened their applicability across diverse tasks, yet specialized domains still require targeted post training. Among existing methods, Group Relative Policy Optimization (GRPO) stands out for its efficiency, leveraging groupwise relative rewards while avoiding costly value function learning. However, GRPO treats candidate responses as independent, overlooking semantic interactions such as complementarity and contradiction. To address this challenge, we first introduce a Structural Causal Model (SCM) that reveals hidden dependencies among candidate responses induced by conditioning on a final integrated output forming a collider structure. Then, our causal analysis leads to two insights: (1) projecting responses onto a causally informed subspace improves prediction quality, and (2) this projection yields a better baseline than query only conditioning. Building on these insights, we propose Group Causal Policy Optimization (GCPO), which integrates causal structure into optimization through two key components: a causally informed reward adjustment and a novel KL regularization term that aligns the policy with a causally projected reference distribution. Comprehensive experimental evaluations demonstrate that GCPO consistently "])</script><script>self.__next_f.push([1,"surpasses existing methods, including GRPO across multiple reasoning benchmarks.b:T6a8,@article{gu2025group,\n  title = {Group causal policy optimization for post-training large language models},\n  author = {Ziyin Gu and Jingyao Wang and Ran Zuo and Chuxiong Sun and Zeen Song and Changwen Zheng and Wenwen Qiang},\n  journal = {AAAI},\n  year = {2026},\n  pdf = {https://arxiv.org/pdf/2508.05428},\n  abstract = {Recent advances in large language models (LLMs) have broadened their applicability across diverse tasks, yet specialized domains still require targeted post training. Among existing methods, Group Relative Policy Optimization (GRPO) stands out for its efficiency, leveraging groupwise relative rewards while avoiding costly value function learning. However, GRPO treats candidate responses as independent, overlooking semantic interactions such as complementarity and contradiction. To address this challenge, we first introduce a Structural Causal Model (SCM) that reveals hidden dependencies among candidate responses induced by conditioning on a final integrated output forming a collider structure. Then, our causal analysis leads to two insights: (1) projecting responses onto a causally informed subspace improves prediction quality, and (2) this projection yields a better baseline than query only conditioning. Building on these insights, we propose Group Causal Policy Optimization (GCPO), which integrates causal structure into optimization through two key components: a causally informed reward adjustment and a novel KL regularization term that aligns the policy with a causally projected reference distribution. Comprehensive experimental evaluations demonstrate that GCPO consistently surpasses existing methods, including GRPO across multiple reasoning benchmarks.}\n}c:T6ca,The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF"])</script><script>self.__next_f.push([1,") have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, we aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), we propose LVICL. LVICL uses our vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, we first use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively. This vector contains compressed, example-related information. Subsequently, during the forward pass, we inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, our vector-injected ICL does not increase prompt length; moreover, adaptively deriving a context vector from examples suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of our approach.d:T819,"])</script><script>self.__next_f.push([1,"@article{zhang2026enhancing,\n  title = {Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning},\n  author = {Jianqi Zhang and Jingyao Wang and Wenwen Qiang and Fanjiang Xu and Changwen Zheng},\n  journal = {WWW},\n  year = {2026},\n  pdf = {https://arxiv.org/pdf/2601.07903},\n  abstract = {The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, we aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), we propose LVICL. LVICL uses our vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, we first use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively. This vector contains compressed, example-related information. Subsequently, during the forward pass, we inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, our vector-injected ICL does not increase prompt length; moreover, adaptively deriving a context vector from examples suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of our approach.}\n}"])</script><script>self.__next_f.push([1,"e:T4e4,Despite Multimodal Large Language Models (MLLMs) having shown impressive capabilities, they may suffer from hallucinations. Empirically, we find that MLLMs attend disproportionately to task-irrelevant background regions compared with text-only LLMs, implying spurious background-answer correlations. We claim and analyze that (i) outcome-based rewards can be an important factor leading to spurious correlations, and (ii) spurious correlations can be an important factor leading to hallucinations. Based on these results, we propose Causal-Oriented Policy Optimization (COPO) to mitigate these spurious correlations, thus addressing the issue of hallucinations. It imposes token-level sufficiency and necessity constraints to measure each inference token's causal contribution, thus ensuring correct and evidence-grounded output. Specifically, we first evaluate each token's causal contribution via a newly proposed causal completeness reward. This reward is then used to construct a causally informed advantage function within the GRPO optimization framework, encouraging the model to focus on tokens that are causally sufficient and necessary for accurate generation. Experimental results across various benchmarks demonstrate the advantages of COPO.f:T61d,@article{guo2025copo,\n  title = {COPO: Causal-Oriented Policy Optimization for Hallucinations of MLLMs},\n  author = {Peizheng Guo and Jingyao Wang and Wenwen Qiang and Jiahuan Zhou and Changwen Zheng and Gang Hua},\n  journal = {CVPR},\n  year = {2026},\n  pdf = {https://arxiv.org/pdf/2508.04182},\n  abstract = {Despite Multimodal Large Language Models (MLLMs) having shown impressive capabilities, they may suffer from hallucinations. Empirically, we find that MLLMs attend disproportionately to task-irrelevant background regions compared with text-only LLMs, implying spurious background-answer correlations. We claim and analyze that (i) outcome-based rewards can be an important factor leading to spurious correlations, and (ii) spurious correlations can be an important factor l"])</script><script>self.__next_f.push([1,"eading to hallucinations. Based on these results, we propose Causal-Oriented Policy Optimization (COPO) to mitigate these spurious correlations, thus addressing the issue of hallucinations. It imposes token-level sufficiency and necessity constraints to measure each inference token's causal contribution, thus ensuring correct and evidence-grounded output. Specifically, we first evaluate each token's causal contribution via a newly proposed causal completeness reward. This reward is then used to construct a causally informed advantage function within the GRPO optimization framework, encouraging the model to focus on tokens that are causally sufficient and necessary for accurate generation. Experimental results across various benchmarks demonstrate the advantages of COPO.}\n}10:T5ec,Multi-Modal Learning (MML) aims to learn effective representations across modalities for accurate predictions. Existing methods typically focus on modality consistency and specificity to learn effective representations. However, from a causal perspective, they may lead to representations that contain insufficient and unnecessary information. To address this, we propose that effective MML representations should be causally sufficient and necessary. Considering practical issues like spurious correlations and modality conflicts, we relax the exogeneity and monotonicity assumptions prevalent in prior works and explore the concepts specific to MML, i.e., Causal Complete Cause (C3). We begin by defining C3, which quantifies the probability of representations being causally sufficient and necessary. We then discuss the identifiability of C3 and introduce an instrumental variable to support identifying C3 with non-exogeneity and non-monotonicity. Building on this, we conduct the C3 measurement, i.e., C3 risk. We propose a twin network to estimate it through (i) the real-world branch: utilizing the instrumental variable for sufficiency, and (ii) the hypothetical-world branch: applying gradient-based counterfactual modeling for necessity. Theoreti"])</script><script>self.__next_f.push([1,"cal analyses confirm its reliability. Based on these results, we propose C3 Regularization, a plug-and-play method that enforces the causal completeness of the learned representations by minimizing C3 risk. Extensive experiments demonstrate its effectiveness.11:T769,@article{wang2024towards,\n  title = {Towards the causal complete cause of multi-modal representation learning},\n  author = {Jingyao Wang and Siyu Zhao and Wenwen Qiang and Jiangmeng Li and Changwen Zheng and Fuchun Sun and Hui Xiong},\n  journal = {ICML},\n  year = {2025},\n  doi = {PMLR 267:65738-65775},\n  pdf = {https://proceedings.mlr.press/v267/wang25ey.html},\n  abstract = {Multi-Modal Learning (MML) aims to learn effective representations across modalities for accurate predictions. Existing methods typically focus on modality consistency and specificity to learn effective representations. However, from a causal perspective, they may lead to representations that contain insufficient and unnecessary information. To address this, we propose that effective MML representations should be causally sufficient and necessary. Considering practical issues like spurious correlations and modality conflicts, we relax the exogeneity and monotonicity assumptions prevalent in prior works and explore the concepts specific to MML, i.e., Causal Complete Cause (C3). We begin by defining C3, which quantifies the probability of representations being causally sufficient and necessary. We then discuss the identifiability of C3 and introduce an instrumental variable to support identifying C3 with non-exogeneity and non-monotonicity. Building on this, we conduct the C3 measurement, i.e., C3 risk. We propose a twin network to estimate it through (i) the real-world branch: utilizing the instrumental variable for sufficiency, and (ii) the hypothetical-world branch: applying gradient-based counterfactual modeling for necessity. Theoretical analyses confirm its reliability. Based on these results, we propose C3 Regularization, a plug-and-play method that enforces the causal comple"])</script><script>self.__next_f.push([1,"teness of the learned representations by minimizing C3 risk. Extensive experiments demonstrate its effectiveness.}\n}12:T53e,Large language models (LLMs) excel at complex tasks thanks to advances in their reasoning abilities. However, existing methods overlook the trade-off between reasoning effectiveness and efficiency, often encouraging unnecessarily long reasoning chains and wasting tokens. To address this, we propose Learning to Think (L2T), an information-theoretic reinforcement fine-tuning framework for LLMs to make the models achieve optimal reasoning with fewer tokens. Specifically, L2T treats each query-response interaction as a hierarchical session of multiple episodes and proposes a universal dense process reward, i.e., quantifies the episode-wise information gain in parameters, requiring no extra annotations or task-specific evaluators. We propose a method to quickly estimate this reward based on PAC-Bayes bounds and the Fisher information matrix. Theoretical analyses show that it significantly reduces computational complexity with high estimation accuracy. By immediately rewarding each episode's contribution and penalizing excessive updates, L2T optimizes the model via reinforcement learning to maximize the use of each episode and achieve effective updates. Empirical results on various reasoning benchmarks and base models demonstrate the advantage of L2T across different tasks, boosting both reasoning effectiveness and efficiency.13:T67c,@article{wang2025learning,\n  title = {Learning to think: Information-theoretic reinforcement fine-tuning for llms},\n  author = {Jingyao Wang and Wenwen Qiang and Zeen Song and Changwen Zheng and Hui Xiong},\n  journal = {NeurIPS},\n  year = {2025},\n  pdf = {https://openreview.net/forum?id=22CqLfjiVl},\n  abstract = {Large language models (LLMs) excel at complex tasks thanks to advances in their reasoning abilities. However, existing methods overlook the trade-off between reasoning effectiveness and efficiency, often encouraging unnecessarily long reasoning chains and was"])</script><script>self.__next_f.push([1,"ting tokens. To address this, we propose Learning to Think (L2T), an information-theoretic reinforcement fine-tuning framework for LLMs to make the models achieve optimal reasoning with fewer tokens. Specifically, L2T treats each query-response interaction as a hierarchical session of multiple episodes and proposes a universal dense process reward, i.e., quantifies the episode-wise information gain in parameters, requiring no extra annotations or task-specific evaluators. We propose a method to quickly estimate this reward based on PAC-Bayes bounds and the Fisher information matrix. Theoretical analyses show that it significantly reduces computational complexity with high estimation accuracy. By immediately rewarding each episode's contribution and penalizing excessive updates, L2T optimizes the model via reinforcement learning to maximize the use of each episode and achieve effective updates. Empirical results on various reasoning benchmarks and base models demonstrate the advantage of L2T across different tasks, boosting both reasoning effectiveness and efficiency.}\n}"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"H-71uq8_hC4utzP-Pgi6g\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/78c4370b96c05382.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/svg+xml\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://jialeliu.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://jialeliu.com\",\"crossOrigin\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preload\",\"as\":\"font\",\"type\":\"font/woff2\",\"href\":\"https://jialeliu.com/fonts/georgiab.woff2\",\"crossOrigin\":\"\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              try {\\n                const theme = localStorage.getItem('theme-storage');\\n                const parsed = theme ? JSON.parse(theme) : null;\\n                const setting = parsed?.state?.theme || 'system';\\n                const prefersDark = typeof window !== 'undefined' \u0026\u0026 window.matchMedia \u0026\u0026 window.matchMedia('(prefers-color-scheme: dark)').matches;\\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\\n                var root = document.documentElement;\\n                root.classList.add(effective);\\n                root.setAttribute('data-theme', effective);\\n              } catch (e) {\\n                var root = document.documentElement;\\n                root.classList.add('light');\\n                root.setAttribute('data-theme', 'light');\\n              }\\n            \"}}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$2\"}}]]}],[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"config\":{\"enabled\":true,\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"mode\":\"auto\",\"fixedLocale\":\"en\",\"persist\":true,\"switcher\":true,\"labels\":{\"en\":\"English\"}},\"children\":[[\"$\",\"$L5\",null,{\"items\":[{\"title\":\"About\",\"type\":\"page\",\"target\":\"about\",\"href\":\"/\"},{\"title\":\"Publications\",\"type\":\"page\",\"target\":\"publications\",\"href\":\"/publications\"},{\"title\":\"Teaching\",\"type\":\"page\",\"target\":\"teaching\",\"href\":\"/teaching\"},{\"title\":\"Awards\",\"type\":\"page\",\"target\":\"awards\",\"href\":\"/awards\"},{\"title\":\"Services\",\"type\":\"page\",\"target\":\"services\",\"href\":\"/services\"},{\"title\":\"CV\",\"type\":\"page\",\"target\":\"cv\",\"href\":\"/cv\"}],\"siteTitle\":\"Jingyao Wang\",\"enableOnePageMode\":false,\"i18n\":\"$0:f:0:1:1:props:children:1:props:children:1:props:children:props:children:props:config\",\"itemsByLocale\":{\"en\":[{\"title\":\"About\",\"type\":\"page\",\"target\":\"about\",\"href\":\"/\"},{\"title\":\"Publications\",\"type\":\"page\",\"target\":\"publications\",\"href\":\"/publications\"},{\"title\":\"Teaching\",\"type\":\"page\",\"target\":\"teaching\",\"href\":\"/teaching\"},{\"title\":\"Awards\",\"type\":\"page\",\"target\":\"awards\",\"href\":\"/awards\"},{\"title\":\"Services\",\"type\":\"page\",\"target\":\"services\",\"href\":\"/services\"},{\"title\":\"CV\",\"type\":\"page\",\"target\":\"cv\",\"href\":\"/cv\"}]},\"siteTitleByLocale\":{\"en\":\"Jingyao Wang\"}}],[\"$\",\"main\",null,{\"className\":\"min-h-screen pt-16 lg:pt-20\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"$L8\",null,{\"lastUpdated\":\"March 1, 2026\",\"lastUpdatedByLocale\":{\"en\":\"March 1, 2026\"},\"defaultLocale\":\"en\"}]]}]}]}]]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L9\",null,{\"dataByLocale\":{\"en\":{\"author\":{\"name\":\"Jingyao Wang\",\"title\":\"PhD Student\",\"institution\":\"Institute of Software Chinese Academy of Sciences\",\"avatar\":\"/bio.jpg\"},\"social\":{\"email\":\"wangjingyao2023@iscas.ac.cn\",\"location\":\"Beijing, China\",\"location_url\":\"https://maps.google.com\",\"location_details\":[\"No.4 South 4th Street, Zhongguancun, Haidian District,\",\"Beijing, 100190, P.R. China\"],\"google_scholar\":\"https://scholar.google.com/citations?user=btThEsYAAAAJ\",\"orcid\":\"https://orcid.org/my-orcid?orcid=0000-0003-1782-8704\",\"github\":\"https://github.com/WangJingyao07\",\"zhihu\":\"https://www.zhihu.com/people/wang-dou-ya-11\"},\"features\":{\"enable_likes\":true,\"enable_one_page_mode\":false},\"enableOnePageMode\":false,\"researchInterests\":[\"MLLM/LLM Reasoning\",\"Embodied AI\",\"Transfer Learning\"],\"pagesToShow\":[{\"type\":\"about\",\"id\":\"about\",\"sections\":[{\"id\":\"about\",\"type\":\"markdown\",\"source\":\"bio.md\",\"title\":\"About\",\"content\":\"I am a second-year PhD student at [ISCAS](http://www.is.cas.cn/), [UCAS](https://www.ucas.ac.cn/), advised by [Prof. Changwen Zheng](https://people.ucas.ac.cn/~cwzheng?language=en)\\n\\nPrior to this, I obtained a B.E. degree with First Class Honours in Beijing University of Technology.\\n\\nMy research interest includes MLLM/LLM Reasoning, Embodied AI, and Transfer Learning. I am maintaining two popular projects on LLM post-training and meta-learning [Awesome-GRPO](https://github.com/WangJingyao07/Awesome-GRPO) and [Awesome-META+](https://wangjingyao07.github.io/Awesome-Meta-Learning-Platform/)\"},{\"id\":\"news\",\"type\":\"list\",\"title\":\"News\",\"source\":\"news.toml\",\"items\":[{\"date\":\"2026-02\",\"content\":\"One work has been accepted by CVPR 2026 ðŸŽ‰\"},{\"date\":\"2026-01\",\"content\":\"One work has been accepted by WWW 2026 ðŸŽ‰\"},{\"date\":\"2025-11\",\"content\":\"One work has been accepted by ASOC ðŸŽ‰\"},{\"date\":\"2025-10\",\"content\":\"Two works have been accepted by AAAI 2026 ðŸŽ‰\"},{\"date\":\"2025-09\",\"content\":\"One work has been accepted by NeurIPS 2025 ðŸŽ‰\"},{\"date\":\"2025-07\",\"content\":\"One work has been accepted by ACMMM 2025 ðŸŽ‰\"},{\"date\":\"2025-05\",\"content\":\"Two works have been accepted by ICML 2025 ðŸŽ‰\"},{\"date\":\"2024-07\",\"content\":\"One work has been accepted by TMM ðŸŽ‰\"},{\"date\":\"2024-05\",\"content\":\"One work has been accepted by IJCV ðŸŽ‰\"},{\"date\":\"2024-04\",\"content\":\"One work has been accepted by IJCAI 2024 ðŸŽ‰\"},{\"date\":\"2023-02\",\"content\":\"One work has been accepted by ACM TOMM ðŸŽ‰\"}]},{\"id\":\"featured_publications\",\"type\":\"publications\",\"title\":\"Selected Publications\",\"filter\":\"selected\",\"limit\":5,\"publications\":[{\"id\":\"gu2025group\",\"title\":\"Group causal policy optimization for post-training large language models\",\"authors\":[{\"name\":\"Ziyin Gu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":true},{\"name\":\"Jingyao Wang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":true},{\"name\":\"Ran Zuo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chuxiong Sun\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zeen Song\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Changwen Zheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenwen Qiang\",\"isHighlighted\":false,\"isCorresponding\":true,\"isCoAuthor\":false}],\"year\":2026,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:dataByLocale:en:pagesToShow:0:sections:2:publications:0:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"AAAI\",\"conference\":\"\",\"code\":\"https://github.com/ML-TASA/GCPO\",\"abstract\":\"$a\",\"description\":\"\",\"selected\":true,\"preview\":\"aaai1.png\",\"bibtex\":\"$b\"},{\"id\":\"zhang2026enhancing\",\"title\":\"Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning\",\"authors\":[{\"name\":\"Jianqi Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":true},{\"name\":\"Jingyao Wang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":true},{\"name\":\"Wenwen Qiang\",\"isHighlighted\":false,\"isCorresponding\":true,\"isCoAuthor\":false},{\"name\":\"Fanjiang Xu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Changwen Zheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2026,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:dataByLocale:en:pagesToShow:0:sections:2:publications:1:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"WWW\",\"conference\":\"\",\"code\":\"https://github.com/jlu-phyComputer/LVICL\",\"abstract\":\"$c\",\"description\":\"\",\"selected\":true,\"preview\":\"www.png\",\"bibtex\":\"$d\"},{\"id\":\"guo2025copo\",\"title\":\"COPO: Causal-Oriented Policy Optimization for Hallucinations of MLLMs\",\"authors\":[{\"name\":\"Peizheng Guo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":true},{\"name\":\"Jingyao Wang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":true},{\"name\":\"Wenwen Qiang\",\"isHighlighted\":false,\"isCorresponding\":true,\"isCoAuthor\":false},{\"name\":\"Jiahuan Zhou\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Changwen Zheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Gang Hua\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2026,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:dataByLocale:en:pagesToShow:0:sections:2:publications:2:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"CVPR\",\"conference\":\"\",\"code\":\"https://github.com/ML-TASA/COPO\",\"abstract\":\"$e\",\"description\":\"\",\"selected\":true,\"preview\":\"cvpr.png\",\"bibtex\":\"$f\"},{\"id\":\"wang2024towards\",\"title\":\"Towards the causal complete cause of multi-modal representation learning\",\"authors\":[{\"name\":\"Jingyao Wang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Siyu Zhao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenwen Qiang\",\"isHighlighted\":false,\"isCorresponding\":true,\"isCoAuthor\":false},{\"name\":\"Jiangmeng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Changwen Zheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Fuchun Sun\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Hui Xiong\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:dataByLocale:en:pagesToShow:0:sections:2:publications:3:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"ICML\",\"conference\":\"\",\"doi\":\"PMLR 267:65738-65775\",\"code\":\"https://wangjingyao07.github.io/C3R.github.io/\",\"abstract\":\"$10\",\"description\":\"\",\"selected\":true,\"preview\":\"icml1.png\",\"bibtex\":\"$11\"},{\"id\":\"wang2025learning\",\"title\":\"Learning to think: Information-theoretic reinforcement fine-tuning for llms\",\"authors\":[{\"name\":\"Jingyao Wang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenwen Qiang\",\"isHighlighted\":false,\"isCorresponding\":true,\"isCoAuthor\":false},{\"name\":\"Zeen Song\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Changwen Zheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Hui Xiong\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$0:f:0:1:2:children:1:props:children:0:props:dataByLocale:en:pagesToShow:0:sections:2:publications:4:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"NeurIPS\",\"conference\":\"\",\"code\":\"https://wangjingyao07.github.io/L2T.github.io/\",\"abstract\":\"$12\",\"description\":\"\",\"selected\":true,\"preview\":\"nips.png\",\"bibtex\":\"$13\"}]}]}]}},\"defaultLocale\":\"en\"}],[\"$\",\"$L14\",null,{\"children\":\"$L15\"}],null,[\"$\",\"$L16\",null,{\"children\":[\"$L17\",\"$L18\",[\"$\",\"$L19\",null,{\"promise\":\"$@1a\"}]]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"JBRAcqBrFwmuPXjsduAcJ\",{\"children\":[[\"$\",\"$L1b\",null,{\"children\":\"$L1c\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$1d\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"1e:\"$Sreact.suspense\"\n1f:I[4911,[],\"AsyncMetadata\"]\n15:[\"$\",\"$1e\",null,{\"fallback\":null,\"children\":[\"$\",\"$L1f\",null,{\"promise\":\"$@20\"}]}]\n"])</script><script>self.__next_f.push([1,"18:null\n"])</script><script>self.__next_f.push([1,"1c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n17:null\n"])</script><script>self.__next_f.push([1,"20:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Jingyao Wang\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"PhD student at the University of Example.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Jingyao Wang\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Jingyao Wang,PhD,Research,Institute of Software Chinese Academy of Sciences\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Jingyao Wang\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Jingyao Wang\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Jingyao Wang\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"PhD student at the University of Example.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:site_name\",\"content\":\"Jingyao Wang's Academic Website\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"Jingyao Wang\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"PhD student at the University of Example.\"}],[\"$\",\"link\",\"14\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}]],\"error\":null,\"digest\":\"$undefined\"}\n1a:{\"metadata\":\"$20:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>