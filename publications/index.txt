1:"$Sreact.fragment"
3:I[3719,["461","static/chunks/461-a9a5d7b05a71d978.js","874","static/chunks/874-6cc630662f3664af.js","291","static/chunks/291-e39730cc9327e39b.js","177","static/chunks/app/layout-4cf029633e6d5428.js"],"ThemeProvider"]
4:I[310,["461","static/chunks/461-a9a5d7b05a71d978.js","874","static/chunks/874-6cc630662f3664af.js","291","static/chunks/291-e39730cc9327e39b.js","177","static/chunks/app/layout-4cf029633e6d5428.js"],"LocaleProvider"]
5:I[4574,["461","static/chunks/461-a9a5d7b05a71d978.js","874","static/chunks/874-6cc630662f3664af.js","291","static/chunks/291-e39730cc9327e39b.js","177","static/chunks/app/layout-4cf029633e6d5428.js"],"default"]
6:I[7555,[],""]
7:I[1295,[],""]
8:I[2548,["461","static/chunks/461-a9a5d7b05a71d978.js","874","static/chunks/874-6cc630662f3664af.js","291","static/chunks/291-e39730cc9327e39b.js","177","static/chunks/app/layout-4cf029633e6d5428.js"],"default"]
a:I[9665,[],"MetadataBoundary"]
c:I[9665,[],"OutletBoundary"]
f:I[4911,[],"AsyncMetadataOutlet"]
11:I[9665,[],"ViewportBoundary"]
13:I[6614,[],""]
:HL["/_next/static/css/78c4370b96c05382.css","style"]
2:T57d,
    try {
      const cfg = {"enabled":true,"locales":["en"],"defaultLocale":"en","mode":"auto","fixedLocale":"en","persist":true,"switcher":true,"labels":{"en":"English"}};
      const storageKey = 'locale-storage';
      const normalize = (value) => typeof value === 'string' ? value.trim().replace('_', '-').toLowerCase() : '';
      const matchLocale = (candidate) => {
        const normalized = normalize(candidate);
        if (!normalized) return null;
        if (cfg.locales.includes(normalized)) return normalized;
        const language = normalized.split('-')[0];
        if (cfg.locales.includes(language)) return language;
        return null;
      };

      let resolved = null;

      if (cfg.persist) {
        resolved = matchLocale(localStorage.getItem(storageKey));
      }

      if (!resolved) {
        if (cfg.mode === 'fixed') {
          resolved = cfg.fixedLocale;
        } else {
          resolved = matchLocale(navigator.language);
        }
      }

      if (!resolved) {
        resolved = cfg.defaultLocale;
      }

      const root = document.documentElement;
      root.lang = resolved;
      root.setAttribute('data-locale', resolved);

      if (cfg.persist) {
        localStorage.setItem(storageKey, resolved);
      }
    } catch (e) {
      const root = document.documentElement;
      root.lang = 'en';
      root.setAttribute('data-locale', 'en');
    }
  0:{"P":null,"b":"H-71uq8_hC4utzP-Pgi6g","p":"","c":["","publications",""],"i":false,"f":[[["",{"children":[["slug","publications","d"],{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/78c4370b96c05382.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"scroll-smooth","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","href":"/favicon.ico","type":"image/svg+xml"}],["$","link",null,{"rel":"dns-prefetch","href":"https://jialeliu.com"}],["$","link",null,{"rel":"preconnect","href":"https://jialeliu.com","crossOrigin":""}],["$","link",null,{"rel":"preload","as":"font","type":"font/woff2","href":"https://jialeliu.com/fonts/georgiab.woff2","crossOrigin":""}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              try {\n                const theme = localStorage.getItem('theme-storage');\n                const parsed = theme ? JSON.parse(theme) : null;\n                const setting = parsed?.state?.theme || 'system';\n                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\n                var root = document.documentElement;\n                root.classList.add(effective);\n                root.setAttribute('data-theme', effective);\n              } catch (e) {\n                var root = document.documentElement;\n                root.classList.add('light');\n                root.setAttribute('data-theme', 'light');\n              }\n            "}}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"$2"}}]]}],["$","body",null,{"className":"font-sans antialiased","children":["$","$L3",null,{"children":["$","$L4",null,{"config":{"enabled":true,"locales":["en"],"defaultLocale":"en","mode":"auto","fixedLocale":"en","persist":true,"switcher":true,"labels":{"en":"English"}},"children":[["$","$L5",null,{"items":[{"title":"About","type":"page","target":"about","href":"/"},{"title":"Publications","type":"page","target":"publications","href":"/publications"},{"title":"Teaching","type":"page","target":"teaching","href":"/teaching"},{"title":"Awards","type":"page","target":"awards","href":"/awards"},{"title":"Services","type":"page","target":"services","href":"/services"},{"title":"CV","type":"page","target":"cv","href":"/cv"}],"siteTitle":"Jingyao Wang","enableOnePageMode":false,"i18n":"$0:f:0:1:1:props:children:1:props:children:1:props:children:props:children:props:config","itemsByLocale":{"en":[{"title":"About","type":"page","target":"about","href":"/"},{"title":"Publications","type":"page","target":"publications","href":"/publications"},{"title":"Teaching","type":"page","target":"teaching","href":"/teaching"},{"title":"Awards","type":"page","target":"awards","href":"/awards"},{"title":"Services","type":"page","target":"services","href":"/services"},{"title":"CV","type":"page","target":"cv","href":"/cv"}]},"siteTitleByLocale":{"en":"Jingyao Wang"}}],["$","main",null,{"className":"min-h-screen pt-16 lg:pt-20","children":["$","$L6",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L8",null,{"lastUpdated":"March 1, 2026","lastUpdatedByLocale":{"en":"March 1, 2026"},"defaultLocale":"en"}]]}]}]}]]}]]}],{"children":[["slug","publications","d"],["$","$1","c",{"children":[null,["$","$L6",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L9",["$","$La",null,{"children":"$Lb"}],null,["$","$Lc",null,{"children":["$Ld","$Le",["$","$Lf",null,{"promise":"$@10"}]]}]]}],{},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","ymrN9cA5iY3t06hDoOwy_",{"children":[["$","$L11",null,{"children":"$L12"}],null]}],null]}],false]],"m":"$undefined","G":["$13","$undefined"],"s":false,"S":true}
14:"$Sreact.suspense"
15:I[4911,[],"AsyncMetadata"]
17:I[2382,["461","static/chunks/461-a9a5d7b05a71d978.js","178","static/chunks/178-595a94b9af1e67b5.js","748","static/chunks/748-97f90665cfe632a2.js","182","static/chunks/app/%5Bslug%5D/page-1017dd8904925b67.js"],"default"]
b:["$","$14",null,{"fallback":null,"children":["$","$L15",null,{"promise":"$@16"}]}]
18:T563,Recent advances in large language models (LLMs) have broadened their applicability across diverse tasks, yet specialized domains still require targeted post training. Among existing methods, Group Relative Policy Optimization (GRPO) stands out for its efficiency, leveraging groupwise relative rewards while avoiding costly value function learning. However, GRPO treats candidate responses as independent, overlooking semantic interactions such as complementarity and contradiction. To address this challenge, we first introduce a Structural Causal Model (SCM) that reveals hidden dependencies among candidate responses induced by conditioning on a final integrated output forming a collider structure. Then, our causal analysis leads to two insights: (1) projecting responses onto a causally informed subspace improves prediction quality, and (2) this projection yields a better baseline than query only conditioning. Building on these insights, we propose Group Causal Policy Optimization (GCPO), which integrates causal structure into optimization through two key components: a causally informed reward adjustment and a novel KL regularization term that aligns the policy with a causally projected reference distribution. Comprehensive experimental evaluations demonstrate that GCPO consistently surpasses existing methods, including GRPO across multiple reasoning benchmarks.19:T6a8,@article{gu2025group,
  title = {Group causal policy optimization for post-training large language models},
  author = {Ziyin Gu and Jingyao Wang and Ran Zuo and Chuxiong Sun and Zeen Song and Changwen Zheng and Wenwen Qiang},
  journal = {AAAI},
  year = {2026},
  pdf = {https://arxiv.org/pdf/2508.05428},
  abstract = {Recent advances in large language models (LLMs) have broadened their applicability across diverse tasks, yet specialized domains still require targeted post training. Among existing methods, Group Relative Policy Optimization (GRPO) stands out for its efficiency, leveraging groupwise relative rewards while avoiding costly value function learning. However, GRPO treats candidate responses as independent, overlooking semantic interactions such as complementarity and contradiction. To address this challenge, we first introduce a Structural Causal Model (SCM) that reveals hidden dependencies among candidate responses induced by conditioning on a final integrated output forming a collider structure. Then, our causal analysis leads to two insights: (1) projecting responses onto a causally informed subspace improves prediction quality, and (2) this projection yields a better baseline than query only conditioning. Building on these insights, we propose Group Causal Policy Optimization (GCPO), which integrates causal structure into optimization through two key components: a causally informed reward adjustment and a novel KL regularization term that aligns the policy with a causally projected reference distribution. Comprehensive experimental evaluations demonstrate that GCPO consistently surpasses existing methods, including GRPO across multiple reasoning benchmarks.}
}1a:T5ae,In this paper, we explore the transferability of SSL by addressing two central questions: (i) what is the representation transferability of SSL, and (ii) how can we effectively model this transferability? Transferability is defined as the ability of a representation learned from one task to support the objective of another. Inspired by the meta-learning paradigm, we construct multiple SSL tasks within each training batch to support explicitly modeling transferability. Based on empirical evidence and causal analysis, we find that although introducing task-level information improves transferability, it is still hindered by task conflict. To address this issue, we propose a Task Conflict Calibration (TC2) method to alleviate the impact of task conflict. Specifically, it first splits batches to create multiple SSL tasks, infusing task-level information. Next, it uses a factor extraction network to produce causal generative factors for all tasks and a weight extraction network to assign dedicated weights to each sample, employing data reconstruction, orthogonality, and sparsity to ensure effectiveness. Finally, TC2 calibrates sample representations during SSL training and integrates into the pipeline via a two-stage bi-level optimization framework to boost the transferability of learned representations. Experimental results on multiple downstream tasks demonstrate that our method consistently improves the transferability of SSL models.1b:T6fc,@article{guo2025exploring,
  title = {Exploring Transferability of Self-Supervised Learning by Task Conflict Calibration},
  author = {Huijie Guo and Jingyao Wang and Peizheng Guo and Xingchen Shen and Changwen Zheng and Wenwen Qiang},
  journal = {AAAI},
  year = {2026},
  pdf = {https://arxiv.org/abs/2511.13787},
  abstract = {In this paper, we explore the transferability of SSL by addressing two central questions: (i) what is the representation transferability of SSL, and (ii) how can we effectively model this transferability? Transferability is defined as the ability of a representation learned from one task to support the objective of another. Inspired by the meta-learning paradigm, we construct multiple SSL tasks within each training batch to support explicitly modeling transferability. Based on empirical evidence and causal analysis, we find that although introducing task-level information improves transferability, it is still hindered by task conflict. To address this issue, we propose a Task Conflict Calibration (TC2) method to alleviate the impact of task conflict. Specifically, it first splits batches to create multiple SSL tasks, infusing task-level information. Next, it uses a factor extraction network to produce causal generative factors for all tasks and a weight extraction network to assign dedicated weights to each sample, employing data reconstruction, orthogonality, and sparsity to ensure effectiveness. Finally, TC2 calibrates sample representations during SSL training and integrates into the pipeline via a two-stage bi-level optimization framework to boost the transferability of learned representations. Experimental results on multiple downstream tasks demonstrate that our method consistently improves the transferability of SSL models.}
}1c:T6ca,The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, we aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), we propose LVICL. LVICL uses our vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, we first use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively. This vector contains compressed, example-related information. Subsequently, during the forward pass, we inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, our vector-injected ICL does not increase prompt length; moreover, adaptively deriving a context vector from examples suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of our approach.1d:T819,@article{zhang2026enhancing,
  title = {Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning},
  author = {Jianqi Zhang and Jingyao Wang and Wenwen Qiang and Fanjiang Xu and Changwen Zheng},
  journal = {WWW},
  year = {2026},
  pdf = {https://arxiv.org/pdf/2601.07903},
  abstract = {The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, we aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), we propose LVICL. LVICL uses our vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, we first use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively. This vector contains compressed, example-related information. Subsequently, during the forward pass, we inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, our vector-injected ICL does not increase prompt length; moreover, adaptively deriving a context vector from examples suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of our approach.}
}1e:T4e4,Despite Multimodal Large Language Models (MLLMs) having shown impressive capabilities, they may suffer from hallucinations. Empirically, we find that MLLMs attend disproportionately to task-irrelevant background regions compared with text-only LLMs, implying spurious background-answer correlations. We claim and analyze that (i) outcome-based rewards can be an important factor leading to spurious correlations, and (ii) spurious correlations can be an important factor leading to hallucinations. Based on these results, we propose Causal-Oriented Policy Optimization (COPO) to mitigate these spurious correlations, thus addressing the issue of hallucinations. It imposes token-level sufficiency and necessity constraints to measure each inference token's causal contribution, thus ensuring correct and evidence-grounded output. Specifically, we first evaluate each token's causal contribution via a newly proposed causal completeness reward. This reward is then used to construct a causally informed advantage function within the GRPO optimization framework, encouraging the model to focus on tokens that are causally sufficient and necessary for accurate generation. Experimental results across various benchmarks demonstrate the advantages of COPO.1f:T61d,@article{guo2025copo,
  title = {COPO: Causal-Oriented Policy Optimization for Hallucinations of MLLMs},
  author = {Peizheng Guo and Jingyao Wang and Wenwen Qiang and Jiahuan Zhou and Changwen Zheng and Gang Hua},
  journal = {CVPR},
  year = {2026},
  pdf = {https://arxiv.org/pdf/2508.04182},
  abstract = {Despite Multimodal Large Language Models (MLLMs) having shown impressive capabilities, they may suffer from hallucinations. Empirically, we find that MLLMs attend disproportionately to task-irrelevant background regions compared with text-only LLMs, implying spurious background-answer correlations. We claim and analyze that (i) outcome-based rewards can be an important factor leading to spurious correlations, and (ii) spurious correlations can be an important factor leading to hallucinations. Based on these results, we propose Causal-Oriented Policy Optimization (COPO) to mitigate these spurious correlations, thus addressing the issue of hallucinations. It imposes token-level sufficiency and necessity constraints to measure each inference token's causal contribution, thus ensuring correct and evidence-grounded output. Specifically, we first evaluate each token's causal contribution via a newly proposed causal completeness reward. This reward is then used to construct a causally informed advantage function within the GRPO optimization framework, encouraging the model to focus on tokens that are causally sufficient and necessary for accurate generation. Experimental results across various benchmarks demonstrate the advantages of COPO.}
}20:T5ec,Multi-Modal Learning (MML) aims to learn effective representations across modalities for accurate predictions. Existing methods typically focus on modality consistency and specificity to learn effective representations. However, from a causal perspective, they may lead to representations that contain insufficient and unnecessary information. To address this, we propose that effective MML representations should be causally sufficient and necessary. Considering practical issues like spurious correlations and modality conflicts, we relax the exogeneity and monotonicity assumptions prevalent in prior works and explore the concepts specific to MML, i.e., Causal Complete Cause (C3). We begin by defining C3, which quantifies the probability of representations being causally sufficient and necessary. We then discuss the identifiability of C3 and introduce an instrumental variable to support identifying C3 with non-exogeneity and non-monotonicity. Building on this, we conduct the C3 measurement, i.e., C3 risk. We propose a twin network to estimate it through (i) the real-world branch: utilizing the instrumental variable for sufficiency, and (ii) the hypothetical-world branch: applying gradient-based counterfactual modeling for necessity. Theoretical analyses confirm its reliability. Based on these results, we propose C3 Regularization, a plug-and-play method that enforces the causal completeness of the learned representations by minimizing C3 risk. Extensive experiments demonstrate its effectiveness.21:T769,@article{wang2024towards,
  title = {Towards the causal complete cause of multi-modal representation learning},
  author = {Jingyao Wang and Siyu Zhao and Wenwen Qiang and Jiangmeng Li and Changwen Zheng and Fuchun Sun and Hui Xiong},
  journal = {ICML},
  year = {2025},
  doi = {PMLR 267:65738-65775},
  pdf = {https://proceedings.mlr.press/v267/wang25ey.html},
  abstract = {Multi-Modal Learning (MML) aims to learn effective representations across modalities for accurate predictions. Existing methods typically focus on modality consistency and specificity to learn effective representations. However, from a causal perspective, they may lead to representations that contain insufficient and unnecessary information. To address this, we propose that effective MML representations should be causally sufficient and necessary. Considering practical issues like spurious correlations and modality conflicts, we relax the exogeneity and monotonicity assumptions prevalent in prior works and explore the concepts specific to MML, i.e., Causal Complete Cause (C3). We begin by defining C3, which quantifies the probability of representations being causally sufficient and necessary. We then discuss the identifiability of C3 and introduce an instrumental variable to support identifying C3 with non-exogeneity and non-monotonicity. Building on this, we conduct the C3 measurement, i.e., C3 risk. We propose a twin network to estimate it through (i) the real-world branch: utilizing the instrumental variable for sufficiency, and (ii) the hypothetical-world branch: applying gradient-based counterfactual modeling for necessity. Theoretical analyses confirm its reliability. Based on these results, we propose C3 Regularization, a plug-and-play method that enforces the causal completeness of the learned representations by minimizing C3 risk. Extensive experiments demonstrate its effectiveness.}
}22:T4d6,In this paper, we focus on the out-of-distribution (OOD) generalization of self-supervised learning (SSL). By analyzing the mini-batch construction during the SSL training phase, we first give one plausible explanation for SSL having OOD generalization. Then, from the perspective of data generation and causal inference, we analyze and conclude that SSL learns spurious correlations during the training process, which leads to a reduction in OOD generalization. To address this issue, we propose a post-intervention distribution (PID) grounded in the Structural Causal Model. PID offers a scenario where the spurious variable and label variable is mutually independent. Besides, we demonstrate that if each mini-batch during SSL training satisfies PID, the resulting SSL model can achieve optimal worst-case OOD performance. This motivates us to develop a batch sampling strategy that enforces PID constraints through the learning of a latent variable model. Through theoretical analysis, we demonstrate the identifiability of the latent variable model and validate the effectiveness of the proposed sampling strategy. Experiments conducted on various downstream OOD tasks demonstrate the effectiveness of the proposed sampling strategy.23:T630,@article{qiang2025out,
  title = {On the Out-of-Distribution Generalization of Self-Supervised Learning},
  author = {Wenwen Qiang and Jingyao Wang and Zeen Song and Jiangmeng Li and Changwen Zheng},
  journal = {ICML},
  year = {2025},
  doi = {PMLR 267:50086-50112},
  pdf = {https://proceedings.mlr.press/v267/qiang25a.html},
  abstract = {In this paper, we focus on the out-of-distribution (OOD) generalization of self-supervised learning (SSL). By analyzing the mini-batch construction during the SSL training phase, we first give one plausible explanation for SSL having OOD generalization. Then, from the perspective of data generation and causal inference, we analyze and conclude that SSL learns spurious correlations during the training process, which leads to a reduction in OOD generalization. To address this issue, we propose a post-intervention distribution (PID) grounded in the Structural Causal Model. PID offers a scenario where the spurious variable and label variable is mutually independent. Besides, we demonstrate that if each mini-batch during SSL training satisfies PID, the resulting SSL model can achieve optimal worst-case OOD performance. This motivates us to develop a batch sampling strategy that enforces PID constraints through the learning of a latent variable model. Through theoretical analysis, we demonstrate the identifiability of the latent variable model and validate the effectiveness of the proposed sampling strategy. Experiments conducted on various downstream OOD tasks demonstrate the effectiveness of the proposed sampling strategy.}
}24:T43b,Scene understanding is one of the core tasks in computer vision, aiming to extract semantic information from images to identify objects, scene categories, and their interrelationships. Although advancements in Vision-Language Models (VLMs) have driven progress in this field, existing VLMs still face challenges in adaptation to unseen complex wide-area scenes. To address the challenges, this paper proposes a Hierarchical Coresets Selection (HCS) mechanism to advance the adaptation of VLMs in complex wide-area scene understanding. It progressively refines the selected regions based on the proposed theoretically guaranteed importance function, which considers utility, representativeness, robustness, and synergy. Without requiring additional fine-tuning, HCS enables VLMs to achieve rapid understandings of unseen scenes at any scale using minimal interpretable regions while mitigating insufficient feature density. HCS is a plug-and-play method that is compatible with any VLM. Experiments demonstrate that HCS achieves superior performance and universality in various tasks.25:T5be,@inproceedings{wang2025advancing,
  title = {Advancing complex wide-area scene understanding with hierarchical coresets selection},
  author = {Jingyao Wang and Yiming Chen and Lingyu Si and Changwen Zheng},
  booktitle = {ACM MM},
  pages = {2663--2672},
  year = {2025},
  doi = {10.1145/3746027.3754707},
  pdf = {https://dl.acm.org/doi/abs/10.1145/3746027.3754707},
  abstract = {Scene understanding is one of the core tasks in computer vision, aiming to extract semantic information from images to identify objects, scene categories, and their interrelationships. Although advancements in Vision-Language Models (VLMs) have driven progress in this field, existing VLMs still face challenges in adaptation to unseen complex wide-area scenes. To address the challenges, this paper proposes a Hierarchical Coresets Selection (HCS) mechanism to advance the adaptation of VLMs in complex wide-area scene understanding. It progressively refines the selected regions based on the proposed theoretically guaranteed importance function, which considers utility, representativeness, robustness, and synergy. Without requiring additional fine-tuning, HCS enables VLMs to achieve rapid understandings of unseen scenes at any scale using minimal interpretable regions while mitigating insufficient feature density. HCS is a plug-and-play method that is compatible with any VLM. Experiments demonstrate that HCS achieves superior performance and universality in various tasks.}
}26:T53e,Large language models (LLMs) excel at complex tasks thanks to advances in their reasoning abilities. However, existing methods overlook the trade-off between reasoning effectiveness and efficiency, often encouraging unnecessarily long reasoning chains and wasting tokens. To address this, we propose Learning to Think (L2T), an information-theoretic reinforcement fine-tuning framework for LLMs to make the models achieve optimal reasoning with fewer tokens. Specifically, L2T treats each query-response interaction as a hierarchical session of multiple episodes and proposes a universal dense process reward, i.e., quantifies the episode-wise information gain in parameters, requiring no extra annotations or task-specific evaluators. We propose a method to quickly estimate this reward based on PAC-Bayes bounds and the Fisher information matrix. Theoretical analyses show that it significantly reduces computational complexity with high estimation accuracy. By immediately rewarding each episode's contribution and penalizing excessive updates, L2T optimizes the model via reinforcement learning to maximize the use of each episode and achieve effective updates. Empirical results on various reasoning benchmarks and base models demonstrate the advantage of L2T across different tasks, boosting both reasoning effectiveness and efficiency.27:T67c,@article{wang2025learning,
  title = {Learning to think: Information-theoretic reinforcement fine-tuning for llms},
  author = {Jingyao Wang and Wenwen Qiang and Zeen Song and Changwen Zheng and Hui Xiong},
  journal = {NeurIPS},
  year = {2025},
  pdf = {https://openreview.net/forum?id=22CqLfjiVl},
  abstract = {Large language models (LLMs) excel at complex tasks thanks to advances in their reasoning abilities. However, existing methods overlook the trade-off between reasoning effectiveness and efficiency, often encouraging unnecessarily long reasoning chains and wasting tokens. To address this, we propose Learning to Think (L2T), an information-theoretic reinforcement fine-tuning framework for LLMs to make the models achieve optimal reasoning with fewer tokens. Specifically, L2T treats each query-response interaction as a hierarchical session of multiple episodes and proposes a universal dense process reward, i.e., quantifies the episode-wise information gain in parameters, requiring no extra annotations or task-specific evaluators. We propose a method to quickly estimate this reward based on PAC-Bayes bounds and the Fisher information matrix. Theoretical analyses show that it significantly reduces computational complexity with high estimation accuracy. By immediately rewarding each episode's contribution and penalizing excessive updates, L2T optimizes the model via reinforcement learning to maximize the use of each episode and achieve effective updates. Empirical results on various reasoning benchmarks and base models demonstrate the advantage of L2T across different tasks, boosting both reasoning effectiveness and efficiency.}
}28:T6be,Micro-expressions (MEs) are involuntary movements revealing people’s hidden feelings, which has attracted significant interests for their objectivity in emotion detection. However, despite their wide applications in various scenarios, micro-expression recognition (MER) remains a challenging problem in real life due to three reasons, including (i) data-level: lack of data and imbalanced classes, (ii) feature-level: subtle, rapidly changing, and complex features of MEs, and (iii) decision-making-level: the impact of individual differences. To address these issues, we propose a dual-branch meta-auxiliary learning method, called LightmanNet, for fast and robust micro-expression recognition. Specifically, LightmanNet learns general MER knowledge from limited data through a dual-branch bi-level optimization process: (i) In the first level, it obtains task-specific MER knowledge by learning in two branches, where the first branch is for learning MER features via primary MER tasks, while the other branch is for guiding the model to obtain discriminative features via auxiliary tasks, i.e., image alignment between micro-expressions and macro-expressions due to their resemblance in both spatial and temporal behavioral patterns. The two branches of learning jointly constrain the model to learn meaningful task-specific MER knowledge while avoiding learning noise or superficial connections between MEs and emotions that may damage its generalization ability. (ii) In the second level, LightmanNet further refines the learned task-specific knowledge, improving model generalization and efficiency. Extensive experiments on various benchmark datasets demonstrate the superior robustness and efficiency of LightmanNet.29:T851,@article{li2025meta,
  title = {Meta-auxiliary learning for micro-expression recognition},
  author = {Yufei Li and Yuxuan Yang and Jingyao Wang and Wenwen Qiang},
  journal = {Applied Soft Computing},
  pages = {114419},
  year = {2025},
  publisher = {Elsevier},
  doi = {10.1016/j.asoc.2025.114419},
  pdf = {https://www.sciencedirect.com/science/article/abs/pii/S1568494625017326},
  abstract = {Micro-expressions (MEs) are involuntary movements revealing people’s hidden feelings, which has attracted significant interests for their objectivity in emotion detection. However, despite their wide applications in various scenarios, micro-expression recognition (MER) remains a challenging problem in real life due to three reasons, including (i) data-level: lack of data and imbalanced classes, (ii) feature-level: subtle, rapidly changing, and complex features of MEs, and (iii) decision-making-level: the impact of individual differences. To address these issues, we propose a dual-branch meta-auxiliary learning method, called LightmanNet, for fast and robust micro-expression recognition. Specifically, LightmanNet learns general MER knowledge from limited data through a dual-branch bi-level optimization process: (i) In the first level, it obtains task-specific MER knowledge by learning in two branches, where the first branch is for learning MER features via primary MER tasks, while the other branch is for guiding the model to obtain discriminative features via auxiliary tasks, i.e., image alignment between micro-expressions and macro-expressions due to their resemblance in both spatial and temporal behavioral patterns. The two branches of learning jointly constrain the model to learn meaningful task-specific MER knowledge while avoiding learning noise or superficial connections between MEs and emotions that may damage its generalization ability. (ii) In the second level, LightmanNet further refines the learned task-specific knowledge, improving model generalization and efficiency. Extensive experiments on various benchmark datasets demonstrate the superior robustness and efficiency of LightmanNet.}
}2a:T4cf,Meta-learning aims to learn general knowledge with diverse training tasks conducted from limited data, and then transfer it to new tasks. It is commonly believed that increasing task diversity will enhance the generalization ability of meta-learning models. However, this paper challenges this view through empirical and theoretical analysis. We obtain three conclusions: (i) there is no universal task sampling strategy that can guarantee the optimal performance of meta-learning models; (ii) over-constraining task diversity may incur the risk of under-fitting or over-fitting during training; and (iii) the generalization performance of meta-learning models are affected by task diversity, task entropy, and task difficulty. Based on this insight, we design a novel task sampler, called Adaptive Sampler (ASr). ASr is a plug-and-play module that can be integrated into any meta-learning framework. It dynamically adjusts task weights according to task diversity, task entropy, and task difficulty, thereby obtaining the optimal probability distribution for meta-training tasks. Finally, we conduct experiments on a series of benchmark datasets across various scenarios, and the results demonstrate that ASr has clear advantages.2b:T694,@article{wang2024towards,
  title = {Towards task sampler learning for meta-learning},
  author = {Jingyao Wang and Wenwen Qiang and Xingzhe Su and Changwen Zheng and Fuchun Sun and Hui Xiong},
  journal = {International Journal of Computer Vision},
  volume = {132},
  number = {12},
  pages = {5534--5564},
  year = {2024},
  doi = {10.1007/s11263-024-02145-0},
  pdf = {https://link.springer.com/article/10.1007/s11263-024-02145-0},
  abstract = {Meta-learning aims to learn general knowledge with diverse training tasks conducted from limited data, and then transfer it to new tasks. It is commonly believed that increasing task diversity will enhance the generalization ability of meta-learning models. However, this paper challenges this view through empirical and theoretical analysis. We obtain three conclusions: (i) there is no universal task sampling strategy that can guarantee the optimal performance of meta-learning models; (ii) over-constraining task diversity may incur the risk of under-fitting or over-fitting during training; and (iii) the generalization performance of meta-learning models are affected by task diversity, task entropy, and task difficulty. Based on this insight, we design a novel task sampler, called Adaptive Sampler (ASr). ASr is a plug-and-play module that can be integrated into any meta-learning framework. It dynamically adjusts task weights according to task diversity, task entropy, and task difficulty, thereby obtaining the optimal probability distribution for meta-training tasks. Finally, we conduct experiments on a series of benchmark datasets across various scenarios, and the results demonstrate that ASr has clear advantages.}
}2c:T655,Freeform handwriting authentication verifies a person's identity from their writing style and habits in messy handwriting data. This technique has gained widespread attention in recent years as a valuable tool for various fields, e.g., fraud prevention and cultural heritage protection. However, it still remains a challenging task in reality due to three reasons: (i) severe damage, (ii) complex high-dimensional features, and (iii) lack of supervision. To address these issues, we propose SherlockNet, an energy-oriented two-branch contrastive self-supervised learning framework for robust and fast freeform handwriting authentication. It consists of four stages: (i) pre-processing: converting manuscripts into energy distributions using a novel plug-and-play energy-oriented operator to eliminate the influence of noise; (ii) generalized pre-training: learning general representation through two-branch momentum-based adaptive contrastive learning with the energy distributions, which handles the high-dimensional features and spatial dependencies of handwriting; (iii) personalized fine-tuning: calibrating the learned knowledge using a small amount of labeled data from downstream tasks; and (iv) practical application: identifying individual handwriting from scrambled, missing, or forged data efficiently and conveniently. Considering the practicality, we construct EN-HA, a novel dataset that simulates data forgery and severe damage in real applications. Finally, we conduct extensive experiments on six benchmark datasets including our EN-HA, and the results prove the robustness and efficiency of SherlockNet.2d:T7fb,@article{wang2024image,
  title = {Image-based freeform handwriting authentication with energy-oriented self-supervised learning},
  author = {Jingyao Wang and Luntian Mou and Changwen Zheng and Wen Gao},
  journal = {IEEE Transactions on Multimedia},
  volume = {27},
  pages = {1397--1409},
  year = {2024},
  doi = {10.1109/TMM.2024.3521807},
  pdf = {https://dl.acm.org/doi/10.1109/TMM.2024.3521807},
  abstract = {Freeform handwriting authentication verifies a person's identity from their writing style and habits in messy handwriting data. This technique has gained widespread attention in recent years as a valuable tool for various fields, e.g., fraud prevention and cultural heritage protection. However, it still remains a challenging task in reality due to three reasons: (i) severe damage, (ii) complex high-dimensional features, and (iii) lack of supervision. To address these issues, we propose SherlockNet, an energy-oriented two-branch contrastive self-supervised learning framework for robust and fast freeform handwriting authentication. It consists of four stages: (i) pre-processing: converting manuscripts into energy distributions using a novel plug-and-play energy-oriented operator to eliminate the influence of noise; (ii) generalized pre-training: learning general representation through two-branch momentum-based adaptive contrastive learning with the energy distributions, which handles the high-dimensional features and spatial dependencies of handwriting; (iii) personalized fine-tuning: calibrating the learned knowledge using a small amount of labeled data from downstream tasks; and (iv) practical application: identifying individual handwriting from scrambled, missing, or forged data efficiently and conveniently. Considering the practicality, we construct EN-HA, a novel dataset that simulates data forgery and severe damage in real applications. Finally, we conduct extensive experiments on six benchmark datasets including our EN-HA, and the results prove the robustness and efficiency of SherlockNet.}
}2e:T613,Efficient recognition of emotions has attracted extensive research interest, which makes new applications in many fields possible, such as human-computer interaction, disease diagnosis, service robots, and so forth. Although existing work on sentiment analysis relying on sensors or unimodal methods performs well for simple contexts like business recommendation and facial expression recognition, it does far below expectations for complex scenes, such as sarcasm, disdain, and metaphors. In this article, we propose a novel two-stage multimodal learning framework, called AMSA, to adaptively learn correlation and complementarity between modalities for dynamic fusion, achieving more stable and precise sentiment analysis results. Specifically, a multiscale attention model with a slice positioning scheme is proposed to get stable quintuplets of sentiment in images, texts, and speeches in the first stage. Then a Transformer-based self-adaptive network is proposed to assign weights flexibly for multimodal fusion in the second stage and update the parameters of the loss function through compensation iteration. To quickly locate key areas for efficient affective computing, a patch-based selection scheme is proposed to iteratively remove redundant information through a novel loss function before fusion. Extensive experiments have been conducted on both machine weakly labeled and manually annotated datasets of self-made Video-SA, CMU-MOSEI, and CMU-MOSI. The results demonstrate the superiority of our approach through comparison with baselines.2f:T7c6,@article{wang2023amsa,
  title = {AMSA: Adaptive multimodal learning for sentiment analysis},
  author = {Jingyao Wang and Luntian Mou and Lei Ma and Tiejun Huang and Wen Gao},
  journal = {ACM Transactions on Multimedia Computing, Communications and Applications},
  volume = {19},
  number = {3s},
  pages = {1--21},
  year = {2023},
  doi = {10.1145/3572915},
  pdf = {https://dl.acm.org/doi/full/10.1145/3572915},
  abstract = {Efficient recognition of emotions has attracted extensive research interest, which makes new applications in many fields possible, such as human-computer interaction, disease diagnosis, service robots, and so forth. Although existing work on sentiment analysis relying on sensors or unimodal methods performs well for simple contexts like business recommendation and facial expression recognition, it does far below expectations for complex scenes, such as sarcasm, disdain, and metaphors. In this article, we propose a novel two-stage multimodal learning framework, called AMSA, to adaptively learn correlation and complementarity between modalities for dynamic fusion, achieving more stable and precise sentiment analysis results. Specifically, a multiscale attention model with a slice positioning scheme is proposed to get stable quintuplets of sentiment in images, texts, and speeches in the first stage. Then a Transformer-based self-adaptive network is proposed to assign weights flexibly for multimodal fusion in the second stage and update the parameters of the loss function through compensation iteration. To quickly locate key areas for efficient affective computing, a patch-based selection scheme is proposed to iteratively remove redundant information through a novel loss function before fusion. Extensive experiments have been conducted on both machine weakly labeled and manually annotated datasets of self-made Video-SA, CMU-MOSEI, and CMU-MOSI. The results demonstrate the superiority of our approach through comparison with baselines.}
}30:T491,Meta-learning enables rapid generalization to new tasks by learning knowledge from various tasks. It is intuitively assumed that as the training progresses, a model will acquire richer knowledge, leading to better generalization performance. However, our experiments reveal an unexpected result: there is negative knowledge transfer between tasks, affecting generalization performance. To explain this phenomenon, we conduct Structural Causal Models (SCMs) for causal analysis. Our investigation uncovers the presence of spurious correlations between task-specific causal factors and labels in meta-learning. Furthermore, the confounding factors differ across different batches. We refer to these confounding factors as "Task Confounders". Based on these findings, we propose a plug-and-play Meta-learning Causal Representation Learner (MetaCRL) to eliminate task confounders. It encodes decoupled generating factors from multiple tasks and utilizes an invariant-based bi-level optimization mechanism to ensure their causality for meta-learning. Extensive experiments on various benchmark datasets demonstrate that our work achieves state-of-the-art (SOTA) performance.31:T5ad,@article{wang2023hacking,
  title = {Hacking task confounder in meta-learning},
  author = {Jingyao Wang and Yi Ren and Zeen Song and Jianqi Zhang and Changwen Zheng and Wenwen Qiang},
  journal = {IJCAI},
  year = {2023},
  pdf = {https://arxiv.org/pdf/2312.05771},
  abstract = {Meta-learning enables rapid generalization to new tasks by learning knowledge from various tasks. It is intuitively assumed that as the training progresses, a model will acquire richer knowledge, leading to better generalization performance. However, our experiments reveal an unexpected result: there is negative knowledge transfer between tasks, affecting generalization performance. To explain this phenomenon, we conduct Structural Causal Models (SCMs) for causal analysis. Our investigation uncovers the presence of spurious correlations between task-specific causal factors and labels in meta-learning. Furthermore, the confounding factors differ across different batches. We refer to these confounding factors as "Task Confounders". Based on these findings, we propose a plug-and-play Meta-learning Causal Representation Learner (MetaCRL) to eliminate task confounders. It encodes decoupled generating factors from multiple tasks and utilizes an invariant-based bi-level optimization mechanism to ensure their causality for meta-learning. Extensive experiments on various benchmark datasets demonstrate that our work achieves state-of-the-art (SOTA) performance.}
}9:["$","$L17",null,{"dataByLocale":{"en":{"type":"publication","config":{"type":"publication","title":"Publications","description":"A collection of my research work.","source":"publications.bib"},"publications":[{"id":"gu2025group","title":"Group causal policy optimization for post-training large language models","authors":[{"name":"Ziyin Gu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":true},{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":true},{"name":"Ran Zuo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Chuxiong Sun","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Zeen Song","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false}],"year":2026,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:0:tags","researchArea":"machine-learning","journal":"AAAI","conference":"","code":"https://github.com/ML-TASA/GCPO","abstract":"$18","description":"","selected":true,"preview":"aaai1.png","bibtex":"$19"},{"id":"guo2025exploring","title":"Exploring Transferability of Self-Supervised Learning by Task Conflict Calibration","authors":[{"name":"Huijie Guo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":true},{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":true},{"name":"Peizheng Guo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xingchen Shen","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false}],"year":2026,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:1:tags","researchArea":"machine-learning","journal":"AAAI","conference":"","code":"https://github.com/PaulGHJ/TC2","abstract":"$1a","description":"","selected":false,"preview":"aaai2.png","bibtex":"$1b"},{"id":"zhang2026enhancing","title":"Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning","authors":[{"name":"Jianqi Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":true},{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":true},{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Fanjiang Xu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2026,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:2:tags","researchArea":"machine-learning","journal":"WWW","conference":"","code":"https://github.com/jlu-phyComputer/LVICL","abstract":"$1c","description":"","selected":true,"preview":"www.png","bibtex":"$1d"},{"id":"guo2025copo","title":"COPO: Causal-Oriented Policy Optimization for Hallucinations of MLLMs","authors":[{"name":"Peizheng Guo","isHighlighted":false,"isCorresponding":false,"isCoAuthor":true},{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":true},{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Jiahuan Zhou","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Gang Hua","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2026,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:3:tags","researchArea":"machine-learning","journal":"CVPR","conference":"","code":"https://github.com/ML-TASA/COPO","abstract":"$1e","description":"","selected":true,"preview":"cvpr.png","bibtex":"$1f"},{"id":"wang2024towards","title":"Towards the causal complete cause of multi-modal representation learning","authors":[{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Siyu Zhao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Jiangmeng Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Fuchun Sun","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Hui Xiong","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:4:tags","researchArea":"machine-learning","journal":"ICML","conference":"","doi":"PMLR 267:65738-65775","code":"https://wangjingyao07.github.io/C3R.github.io/","abstract":"$20","description":"","selected":true,"preview":"icml1.png","bibtex":"$21"},{"id":"qiang2025out","title":"On the Out-of-Distribution Generalization of Self-Supervised Learning","authors":[{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":true},{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":true},{"name":"Zeen Song","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiangmeng Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:5:tags","researchArea":"machine-learning","journal":"ICML","conference":"","doi":"PMLR 267:50086-50112","code":"https://github.com/ML-TASA/PID-SSL","abstract":"$22","description":"","selected":false,"preview":"icml2.png","bibtex":"$23"},{"id":"wang2025advancing","title":"Advancing complex wide-area scene understanding with hierarchical coresets selection","authors":[{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Yiming Chen","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Lingyu Si","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"conference","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:6:tags","researchArea":"machine-learning","journal":"","conference":"ACM MM","pages":"2663--2672","doi":"10.1145/3746027.3754707","code":"https://wangjingyao07.github.io/HCS.github.io/","abstract":"$24","description":"","selected":false,"preview":"acmmm.png","bibtex":"$25"},{"id":"wang2025learning","title":"Learning to think: Information-theoretic reinforcement fine-tuning for llms","authors":[{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Zeen Song","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Hui Xiong","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:7:tags","researchArea":"machine-learning","journal":"NeurIPS","conference":"","code":"https://wangjingyao07.github.io/L2T.github.io/","abstract":"$26","description":"","selected":true,"preview":"nips.png","bibtex":"$27"},{"id":"li2025meta","title":"Meta-auxiliary learning for micro-expression recognition","authors":[{"name":"Yufei Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Yuxuan Yang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":true,"isCoAuthor":false},{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:8:tags","researchArea":"machine-learning","journal":"Applied Soft Computing","conference":"","pages":"114419","doi":"10.1016/j.asoc.2025.114419","abstract":"$28","description":"","selected":false,"preview":"asoc.png","bibtex":"$29"},{"id":"wang2024towards","title":"Towards task sampler learning for meta-learning","authors":[{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Xingzhe Su","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Fuchun Sun","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Hui Xiong","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:9:tags","researchArea":"machine-learning","journal":"International Journal of Computer Vision","conference":"","volume":"132","issue":"12","pages":"5534--5564","doi":"10.1007/s11263-024-02145-0","code":"https://github.com/WangJingyao07/Adaptive-Sampler","abstract":"$2a","description":"","selected":true,"preview":"ijcv.png","bibtex":"$2b"},{"id":"wang2024image","title":"Image-based freeform handwriting authentication with energy-oriented self-supervised learning","authors":[{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Luntian Mou","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Wen Gao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:10:tags","researchArea":"machine-learning","journal":"IEEE Transactions on Multimedia","conference":"","volume":"27","pages":"1397--1409","doi":"10.1109/TMM.2024.3521807","abstract":"$2c","description":"","selected":true,"preview":"tmm.png","bibtex":"$2d"},{"id":"wang2023amsa","title":"AMSA: Adaptive multimodal learning for sentiment analysis","authors":[{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Luntian Mou","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Lei Ma","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Tiejun Huang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Wen Gao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2023,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:11:tags","researchArea":"machine-learning","journal":"ACM Transactions on Multimedia Computing, Communications and Applications","conference":"","volume":"19","issue":"3s","pages":"1--21","doi":"10.1145/3572915","code":"https://github.com/WangJingyao07/Multimodal-Sentiment-Analysis-for-Health-Navigation","abstract":"$2e","description":"","selected":false,"preview":"tomm.png","bibtex":"$2f"},{"id":"wang2023hacking","title":"Hacking task confounder in meta-learning","authors":[{"name":"Jingyao Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Yi Ren","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Zeen Song","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jianqi Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Changwen Zheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Wenwen Qiang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false}],"year":2023,"type":"journal","status":"published","tags":[],"keywords":"$9:props:dataByLocale:en:publications:12:tags","researchArea":"machine-learning","journal":"IJCAI","conference":"","code":"https://github.com/WangJingyao07/MetaCRL","abstract":"$30","description":"","selected":false,"preview":"ijcai.png","bibtex":"$31"}]}},"defaultLocale":"en"}]
e:null
12:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
d:null
16:{"metadata":[["$","title","0",{"children":"Publications | Jingyao Wang"}],["$","meta","1",{"name":"description","content":"A collection of my research work."}],["$","meta","2",{"name":"author","content":"Jingyao Wang"}],["$","meta","3",{"name":"keywords","content":"Jingyao Wang,PhD,Research,Institute of Software Chinese Academy of Sciences"}],["$","meta","4",{"name":"creator","content":"Jingyao Wang"}],["$","meta","5",{"name":"publisher","content":"Jingyao Wang"}],["$","meta","6",{"property":"og:title","content":"Jingyao Wang"}],["$","meta","7",{"property":"og:description","content":"PhD student at the University of Example."}],["$","meta","8",{"property":"og:site_name","content":"Jingyao Wang's Academic Website"}],["$","meta","9",{"property":"og:locale","content":"en_US"}],["$","meta","10",{"property":"og:type","content":"website"}],["$","meta","11",{"name":"twitter:card","content":"summary"}],["$","meta","12",{"name":"twitter:title","content":"Jingyao Wang"}],["$","meta","13",{"name":"twitter:description","content":"PhD student at the University of Example."}],["$","link","14",{"rel":"icon","href":"/favicon.ico"}]],"error":null,"digest":"$undefined"}
10:{"metadata":"$16:metadata","error":null,"digest":"$undefined"}
